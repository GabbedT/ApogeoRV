## Index 

* [Introduction](#introduction)
* [Register File](#register-file)
* [Scheduler](#scheduler)

---

## Introduction 

The **issue stage** is the last pipeline stage before the *back end* of the CPU begins. Here the instructions read their operands and waits to be issued to the execution unit. 
RAW and WAW dependencies are resolved here by the **scheduler** to ensure the program coherency and allow the out of order execution to be transparent to the programmer. If a dependency is detected, the entire *front end* is stalled and the instruction waits until it's cleared.

Simultaneously the operands are readed from the register file, depending on the operation the register or the immediate coming from the *decode stage* is selected. An adder is present here to compute the target address for memory and branch instructions, the computed address can be used as operand for memory operations.

The **reorder buffer tag** is generated by a counter that increments its value by one each time an instruction is issued. With this, the **instruction packet can be assembled** and sent to the execution unit once the instruction leaves the issue unit.

---

## Register File 

The register file is the component that holds most of the **architectural state** of a CPU. The register file stores temporary results of computational operations, which are later used for subsequent computations. Each entry of the register file is also called **GPR** (General Purpouse Register).

In the RISC-V architecture, a set of 32 registers, each consisting of 32 bits (in RV32), is defined. Every instruction in RISC-V architecture *reads two operands as registers and writes the result back into the register file*. The 32 registers can be used as either general-purpose registers or special-purpose registers. General-purpose registers are used to store temporary data, whereas special-purpose registers are used to hold information relevant to specific instructions or processor operations (specified in the RISC-V specifications), however from the microarchitectural point of view each GPR is the same and they are not differentiated.

The memory used to implement the registers must have **two read ports and one write port**, with each port being independent and having its own address. The two read ports allow simultaneous reading of register values, which helps speed up the computation process significantly.

The **write port completes its operation after one clock cycle**, while the **read ports are combinational**, meaning that the result is available instantly. This is because the register values are needed to compute the target address of memory and branch instructions.

When designing an FPGA, it is ideal to build the register file with LUTRAM that allows for combinational read. LUTRAM (Look-Up Table RAM) is a type of memory in FPGAs that provides fast read access to memory. Since FPGAs usually don't implement 1W / 2R LUTRAMs, two 32x32 registers are instantiated, with each one representing a single read port. The write ports are connected together with the writeback stage so that the two registers have the same values. 

---

## Scheduler 

The scheduler is certainly the most critical component of the *issue stage*, its task it to **keep track of the state of the execution unit** by saving destination registers, functional unit status and time before the unit produces a valid result. The algorithm used for the scheduler is the **scoreboard**. The scoreboard can be stalled if one of the buffer in the commit stage is full, then the entire pipeline before commit stage is stalled.

It takes as input the valid bit for each functional unit to determine to which unit the instruction must be issued. Based on the bit set (only one bit is active at time), it determine the **latency of the operation**. Here the latency is the **clock cycles needed from the arrival of the valid bit to the result production** (before entering in the commit stage). For example ALU has a latency of 0 cycles since is combinational, BMU has a latency of 1 because it has 1 pipeline register.

The latency is incremented by 1 because of the **bypass stage** (so ALU at the end it will have a latency of 1 cycle).

Here are the latency of the units: 
* ALU: 0
* CSR: 0
* MUL: 5
* DIV: 35
* BMU: 1

For each functional unit (**except the ALU and CSR**), the scheduler keep tracks of:

* **Status**: if the unit is executing or not.
* **Register destination**.
* **Clock cycles remaining** before the result is produced.

When the instruction gets issued to a functional unit:
* A counter is **loaded with the corresponding latency value plus 1**. Then it will be decremented each clock cycle if the scheduler is not stalled.
* The **status bit is set to true** to indicate that the functional unit is executing data.
* The destination register is loaded.

The scheduler does three check: 
* **RAW Hazard**: each source register of the instruction to issue is compared to every register destination.
* **WAW Hazard**: the latency computed from the valid bit set is compared against every counter. Also the register destination of the instruction to issue is compared to every register destination.
* **Structural Hazard**: if the instruction needs to issue to a sequential unit and that unit is currently not idle.

If a match from one of those hazards occours the instruction can't be issued and the **entire front end is stalled**.